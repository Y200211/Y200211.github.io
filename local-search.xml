<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MySQL | 如何减少行级锁对性能的影响</title>
    <link href="/2023/06/17/07%E8%AE%B2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E8%A1%8C%E7%BA%A7%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/"/>
    <url>/2023/06/17/07%E8%AE%B2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E8%A1%8C%E7%BA%A7%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/</url>
    
    <content type="html"><![CDATA[<p>继续把该讲内容总结为几个问题, 大家复习的时候可以先尝试回答这些问题检查自己的掌握程度:  </p><ol><li><p>两阶段锁的概念是什么? 对事务使用有什么帮助?  </p><p> 两阶锁其实不是一个锁，而是一个协议。当两个事务中都对同一行的数据进行更新的时候，后更新的那个事务会进行阻塞，等待前一个事务提交后再进行更新操作，这就是两阶段锁的定义。知道这点后我们可以对事务进行优化，通过把冲突的操作移动到事务的最后，使得事务中加锁的时间最小，从而使得造成冲突的概率变小。</p></li><li><p>死锁的概念是什么? 举例说明出现死锁的情况.  </p><p> 在本章中，死锁的概念是事务A和事务B都在等对方释放，举个例子的话，如下图：</p><p> <img src="https://secure2.wostatic.cn/static/iSQ3ebiNCiXQg7uqqch2ZJ/image.png?auth_key=1687007122-4BJSxCn6SevMt7jPtH23HM-0-fb4e22c8ed4eb36d0c0b94d1f6151eeb"></p></li><li><p>死锁的处理策略有哪两种?  </p><p> 一种是等到超时，这个时间由参数innodb_lock_wait_timeout来设置。另一种是发起死锁检测，如果发现了死锁之后，就会把其中一个事务回滚，让另一个事物先执行。</p></li><li><p>等待超时处理死锁的机制什么?有什么局限?  </p><p> 等待超时这个策略听起来就不太靠谱，因为这个时间的长度很难把握，如果太长的话，用户可能受不了；如果太短的话，很有可能误伤了其他本身需要时间较长的操作，所以这个策略还是不靠谱的。</p></li><li><p>死锁检测处理死锁的机制是什么? 有什么局限?  </p><p> 死锁检测的机制就是检测到有加锁的事务了，就去遍历他所需要的操作的行有没有加锁的，这个操作的时间复杂度是O（n），开销还是很大的，可以说并发执行的线程越多，CPU的压力就越大。</p></li><li><p>有哪些思路可以解决热点更新导致的并发问题?</p><p> 既然是由于并发产生的问题，控制并发度就可以了。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>锁</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL | 全局锁和表锁</title>
    <link href="/2023/06/14/06%E8%AE%B2%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81/"/>
    <url>/2023/06/14/06%E8%AE%B2%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81/</url>
    
    <content type="html"><![CDATA[<p>首先介绍一下读锁和写锁。读锁（共享锁）不允许别人写但是允许和别人一起读；写锁（排他锁）既不允许写也不允许读，所以叫排他锁。只读取数据的时候一般是加读锁，增删改数据的时候一般加写锁。</p><ul><li><p>全局锁</p><p>  全局锁就是把整个库锁住，一般用来进行全局逻辑备份，让全局都处于只读状态，这么做是为了在操作的时候视图逻辑时间点一致。说到一致性视图，官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>  你也许会问，<strong>既然要全库只读，为什么不使用set global readonly&#x3D;true的方式呢</strong>？</p><ul><li>第一是有些时候会通过global这个参数来判断是主库还是从库，所以容易造成错误</li><li>第二是有些时候发生异常断开后，这个参数并不会自己复位，会一直保持不可写的状态</li></ul></li><li><p>表级锁</p><p>  表锁有两种，一种是需要显式调用的，一种是非显式调用的</p><ul><li><strong>表锁的语法是 lock tables … read&#x2F;write。</strong></li><li><strong>另一类表级的锁是MDL（metadata lock)。</strong>MDL不需要显式使用，在访问一个表的时候会被自动加上。</li></ul></li></ul><p>MDL上有个错误很容易发生，容易在操作小表的时候发生问题。当MDL锁住的时候，有想改写表中数据的需要，这时就会阻塞，当后面再有来申请读锁的时候就会不断重试，很快线程就会爆</p><p>基于上面的分析，我们来讨论一个问题，<strong>如何安全地给小表加字段？</strong></p><p>首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。</p><p>但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？</p><p>这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。</p><p>MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT&#x2F;WAIT n这个语法。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>锁</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL | 深入浅出索引</title>
    <link href="/2023/06/07/04%E8%AE%B2%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95/"/>
    <url>/2023/06/07/04%E8%AE%B2%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95/</url>
    
    <content type="html"><![CDATA[<p>索引一般有三种常见的实现：哈希表，有序数组，N叉树</p><ul><li><p>哈希表</p><p>  一般是给一个想查的值，然后通过哈希函数算出来N，通过这个N就能取到想要的值。有时候两个数算出来都是N，这就是哈希冲突，这时就会在后面加一个链表。哈希表的增删改时间复杂度都是O(n)，但是区域查询会很麻烦，因为它是无序的，区域内的数每个都要查一次，所以，<strong>哈希表这种结构适用于只有等值查询的场景</strong>，比如Memcached及其他一些NoSQL引擎。</p><p>  总结一下：</p><pre><code class="hljs">增删改的速度很快，等值查询也很快，但是范围查询不行</code></pre></li><li><p>有序数组</p><ul><li><p>优点：</p><p>  因为是有序的数组，所以查询的时候可以用二分法，时间复杂度是O(logN)，也很适合范围查询，先查最左面的数，然后依次往后遍历，一直查到右面的边界即可。</p></li><li><p>缺点：</p><p>  插入很麻烦，因为要维持有序性，所以当插入的数在数组中间的时候，后面的数都要依次向后面挪动，效率很低。</p></li></ul><p>  所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。</p></li></ul><p>上面这两种实现都有很明显的缺点，所以为了解决这些缺点，引出了第三种，请看下文。</p><ul><li><p>二叉搜索树：</p><p>  要说N叉树，先说说二叉搜索树树为什么不行。因为搜索树的查询时间复杂度是O(logN)，但是插入的复杂度也是O(logN)，那为什么不用二叉搜索树呢。因为我们的索引不止存在于内存中，还在磁盘中，而磁盘IO读取数据块的时间大约是10ms，所以我们应该减少对数据快的切换读取，所以引入了N叉树，B树，B+树。</p></li><li><p>N叉搜索树：</p><p>  就是俗称的B树，它的N一般是1200，也就是说他是1200叉树，当他的树高是4的时候，就可以存1200^3。</p></li><li><p><strong>B+树：</strong></p><p>  InnoDB中的索引模型，首先先解释一下B树和B+树的区别：</p><ul><li>B+树的数据都存在叶子结点，而B树的数据在各个节点，B+树这个行为更适合在磁盘储存这种外部储存模式，因为在每个节点都有数据会使得数据块存不下几个节点之后不得不分页，这导致了树的高度增加，磁盘IO次数增加，效率降低</li><li>B+树的叶子结点保证了有序性的同时，还用指针连接起来了，这保证了范围查询时不用反复查找，直接遍历即可。</li></ul></li></ul><p>说完了索引的底层存储类型，接下来看看实践过程中会遇到的一些问题。</p><p>先看看索引的简单分类：</p><ul><li>主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。</li><li>非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。</li></ul><p>根据上面的索引结构说明，我们来讨论一个问题：<strong>基于主键索引和普通索引的查询有什么区别？</strong></p><ul><li>如果语句是select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。</li></ul><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p><h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h2><p>首先来讨论一下自增主键的作用：</p><ul><li>增加节点的时候，由于主键是自增主键，所以直接在尾巴添加即可，不需要在中间插入，会导致页分裂问题，而且自增主键占的位置也很小（和一般别的唯一索引相比）。删除同理，但是一般会使用伪删除，防止页合并发生。</li><li>主键所占得位置小还有一个好处，就是会节省非聚簇索引（非主键索引）的大小，因为其他的一般索引叶子结点都是主键（用于回表）。</li></ul><p>虽然自增主键有这么多好处，但是凡事不绝对，下面这个场景就使用非自增ID比较好：</p><ul><li>如果只有一个索引，并且这个索引是唯一索引，那么用这个唯一的字段作为主键比较好，因为避免了查两次表，如果要用自增ID的话，需要先查一下唯一的字段的索引来获取到自增ID，再用自增ID查看完整的数据。</li></ul><h2 id="覆盖索引和联合索引的区别"><a href="#覆盖索引和联合索引的区别" class="headerlink" title="覆盖索引和联合索引的区别"></a><strong>覆盖索引和联合索引的区别</strong></h2><ul><li>覆盖索引就是在二级索引中已经能拿到所需要的所有数据，不用回表，达成这个要求的就是覆盖索引，即使二级索引不是联合索引也可能达成。</li><li>联合索引就是把几个列合在一起构建一个索引，这样的索引更有可能达成覆盖索引，但是需要注意的是有最左前缀法则，查询的时候字段的顺序一定要注意。（最左原则的原理就是，因为联合索引的有序性是从左往右的优先度的，所以查的时候必须先从左边开始，否则用不了联合索引）</li></ul><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h2><p>简单来说就是尽可能的提早把不符合条件的数据过滤掉，看下面的例子：</p><p>检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”</p><p><img src="https://secure2.wostatic.cn/static/pKWUQG4m83cLKN3rteUge7/image.png?auth_key=1686117385-iS2uPDMc7AXsJ2qiih4z46-0-e597a022c961068d58a12a8bf839f15f&file_size=258947"></p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>索引</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>go语言内存管理&amp;优化思路</title>
    <link href="/2023/06/07/go%E8%AF%AD%E8%A8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&amp;%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF/"/>
    <url>/2023/06/07/go%E8%AF%AD%E8%A8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&amp;%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF/</url>
    
    <content type="html"><![CDATA[<blockquote><p>由于滴滴二面的时候提到了GC，吟唱完之后面试官问我实践开发中怎么减少GC的次数来提高性能，只答出来一个有的时候可以传值代替穿指针（原因不解释了），面试官问还有吗，彻底不会了，正好参加字节这个青训营，有一节课讲到这里了，做一下笔记吧，要不又白看了。</p></blockquote><h2 id="1-1-内存分配—分块"><a href="#1-1-内存分配—分块" class="headerlink" title="1.1 内存分配—分块"></a>1.1 内存分配—分块</h2><p>首先讲一讲go语言是怎么做对象的内存分配的，他是把内存分成不同大小的块，然后看对象的大小来决定要把它放进多大的块里，再把这些块分类，一类是没有指针的对象（不需要GC），一类是有指针的对象（需要GC）。所以根据上面这些条件找出一个合适的块，就完成了一次内存分配</p><h2 id="1-2-Go内存管理优化"><a href="#1-2-Go内存管理优化" class="headerlink" title="1.2 Go内存管理优化"></a>1.2 Go内存管理优化</h2><p>要进行优化，就先要知道他有什么问题和我们常用的场景有哪些：</p><ol><li>对象分配是非常高频的操作，每秒分配GB级别的内存</li><li>小对象占比高，需要对小对象进行特定的优化</li><li>Go本身的内存分配路径非常长，非常耗时</li></ol><h2 id="1-3-优化方案：Balance-GC"><a href="#1-3-优化方案：Balance-GC" class="headerlink" title="1.3 优化方案：Balance GC"></a>1.3 优化方案：Balance GC</h2><ol><li>把每个g（goroutine）都绑定一大块内存（1KB），称作goroutine allocation buffer(GAB)</li><li>然后再这一块大内存上进行小对象的分配，这样就不会和别的冲突，减短了分配路径</li><li>进而可以进行指针对象风格的分配，如下图：</li></ol><p><img src="https://secure2.wostatic.cn/static/41F258iLy1tLaBAQYwvdb/image.png?auth_key=1687008602-dLWV8uyXSKHHLBUTuG9fHu-0-987d5529abfda2c7dce7f76e2e621db9"></p><p>当然这个大块内存的分配走的还是正常的分配路径，但是里面的小对象分配会简单高效很多，所以本质上是将多个小对象的分配合并成了一个大对象的分配。</p><p>这又引出了另外一个问题，就是有的时候一大块内存中只有几个小对象，这导致了整块内存都不能释放，下面是解决方案：</p><p>  当GBA的数量到一个值的时候，对GBA进行清理，会把散落的对象集中起来，然后把原来的内存释放掉。</p><p>  <img src="https://secure2.wostatic.cn/static/e2WKcPWREfYojmt31kjY33/image.png?auth_key=1687008602-uFnU8kxuWA5RPFfgALcPhc-0-878c1b7b5c45fa0c8711f9d48e6e96db"></p><p>总结：</p><p>Go对象分配的性能问题：</p><ul><li>分配路经过长</li><li>小对象居多</li></ul><p>解决方案Balance GC：</p><ul><li>指针碰撞风格的内存分配</li><li>实现了copying GC（就是上面那张图）</li></ul><p>接下来回到问题本身，怎么优化</p><ol><li>首先想到的就是暴力做法，直接把执行GC的阈值降低就行了，简单来说就是让GC执行的更频繁，这样内存也不会爆的太快。</li><li>对象池技术，对象池是预先分配和重用对象的集合，避免频繁地创建和销毁对象。通过使用对象池，可以减少新对象的分配次数，从而减少 GC 的压力。</li><li>使用并发和异步技术：通过并发和异步的设计，可以更好地隐藏 GC 的开销。例如，使用 Goroutine 进行并发处理，利用通道（Channel）进行数据传递，将 GC 的负担分摊到不同的时间段和线程中。</li></ol><p><img src="https://secure2.wostatic.cn/static/63Dn45rcE1t7tAUH1ttbPM/image.png?auth_key=1687008602-suisnJZUidydCfi55rygUG-0-7a22821ff36da88076ab53cf98c7d86e"></p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
      <tag>GC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL | 事务隔离</title>
    <link href="/2023/06/06/03%E8%AE%B2%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/"/>
    <url>/2023/06/06/03%E8%AE%B2%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/</url>
    
    <content type="html"><![CDATA[<ul><li>首先先上广为人知的知识点：</li></ul><p>1、事务的特性：原子性（A）、一致性（C）、隔离性（I）、持久性（D）<br>2、多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读<br>3、事务隔离级别：读未提交、读提交、可重复读、串行化<br>4、不同事务隔离级别的区别：  </p><pre><code class="hljs">读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到  </code></pre><p>读提交：一个事务提交之后，它所做的变更才可以被别的事务看到<br>可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的<br>串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行</p><ul><li><p>四种隔离级别的实现方法：</p><ul><li>读未提交：直接返回最新值，没有视图的概念</li><li>读提交：每个SQL语句生成一个视图</li><li>可重复度：每个事务开始的时候生成一个视图，一直用到事务结束</li><li>串行化：简单来说就是加锁，用加锁的方式避免并行操作</li></ul></li><li><p>四种隔离级别具体的使用场景：</p><ul><li>01: Read uncommitted 读未提交; 公司发工资了，领导把5000元打到singo的账号上，但是该事务并未提交，而singo正好去查看账户，发现工资已经到账，是5000元整，非常高兴。可是不幸的是，领导发现发给singo的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后singo实际的工资只有2000元，singo空欢喜一场。</li><li>02:Read committed 读已提交; singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，为何……</li><li>03:Repeatable read 重复读 当singo拿着工资卡去消费时，一旦系统开始读取工资卡信息（即事务开始），singo的老婆就不可能对该记录进行修改，也就是singo的老婆不能在此时转账。</li><li>04：重复读可能出现<a href="https://so.csdn.net/so/search?q=%E5%B9%BB%E8%AF%BB&spm=1001.2101.3001.7020">幻读</a>： singo的老婆工作在银行部门，她时常通过银行内部系统查看singo的信用卡消费记录。有一天，她正在查询到singo当月信用卡的总消费金额（select sum(amount) from transaction where month &#x3D; 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction … ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出现了幻觉，幻读就这样产生了。（幻读是事务执行过程中，别的事务进行插入操作，从而使原来的查询事务出现“幻觉”）</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>日志</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL | 日志系统</title>
    <link href="/2023/06/05/02%E8%AE%B2%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    <url>/2023/06/05/02%E8%AE%B2%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>首先介绍两个日志的基本概念，一个是物理操作，一个是逻辑操作。</p><ul><li><p>物理操作</p><p>  物理操作是对数据库底层数据存储结构的操作，即对数据在物理存储设备上的读写操作，例如读取和写入具体的数据块、页或者记录等。物理操作直接访问存储设备，包括对设备的读取、写入、删除操作等，因此它对应着实际的存储结构。 因为redolog是Innodb中特有的日志，又因为存储引擎在最底层，所以redolog是物理操作。</p></li><li><p>逻辑操作</p><p>  逻辑操作是对数据库中对象的操作，例如对表中数据的增删改查等操作，它是基于用户或应用程序想要执行的实际操作进行的操作。逻辑操作是以SQL语言的形式体现的，根据不同的SQL语句可以进行增删改查等逻辑操作，而不考虑数据的存储细节和实际操作过程。因为binlog是mysql中自带的，所以在上层，只能进行逻辑操作的记录。</p></li></ul><p>接下来来讲两个日志，一个是redolog，一个是binlog。</p><ul><li><p>redolog（主要作用是crash-safe）</p><p>  redolog出现的目的是完成事物的一致性，当事务进行到一半的时候mysql突然崩溃了，redolog可以进行回滚操作，它本身是以二进制的方式存储的。还有一个持久化的目的，因为每次想把操作持久化都要进行磁盘的读写，但是磁盘读写太慢了，所以先在内存记录下来，当系统不忙的时候在写到磁盘上去。其实就是MySQL里经常说到的WAL技术，WAL的全称是Write-Ahead Logging。因为redolog是物理操作，所以存的都是结果如何变更，不会存具体的逻辑。它的存储方式如下图：</p><p>  checkpoint表示从哪里开始，write pos表示在哪里结束</p><p>  <img src="https://secure2.wostatic.cn/static/6QEVzctFnb9hojQNRBAch6/image.png?auth_key=1686117503-gu4RodEvCheszVu7tv2Xyc-0-ab77d042d9fde44e305ee1556f04c3d5&file_size=149386"></p></li><li><p>binlog（主要作用是归档，即回到某一个时间点的数据库状态）</p><p>  底层使用二进制存储的语句逻辑，加入想回到中午那时候的数据库，就需要找到中午之前最近的全局备份，然后执行binlog到中午即可。</p><p>  常见的 binlog 格式有三种：statement、row 和 mixed，不同格式的 binlog 会记录不同粒度的信息。</p><ul><li>statement 格式是最常见的 binlog 格式，它记录的是 SQL 语句的执行信息。也就是说，如果一个 SQL 语句要修改多行数据，那它只需要记录这条语句本身，而不需要记录每行数据的修改情况。这种格式下日志量小，但是存在一定的不一致性。</li><li>row 格式记录的是每一行数据修改的详细情况，一条修改命令会被具体记录为几条将要修改数据的语句。这种格式下数据更为详细，但是日志量较大。</li><li>mixed 格式在 statement 和 row 格式之间切换，刚开始以 statement 方式记录日志，当出现不支持语句级别的操作时，会自动转化为 row 格式记录。mixed 格式将 statement 和 row 格式的优点结合起来，同时也存在对应的缺点。</li></ul></li></ul><p>这两个日志相结合，使用的时候需要保证一致性，如果在两个日志中间crash了，保证不了一致性，所以引入了一个类似事务的操作，如下图：</p><p>将redo log的写入拆成了两个步骤：prepare和commit，这就是”两阶段提交”。</p><p><img src="https://secure2.wostatic.cn/static/cAC2ALzsaU3uzNME5igau5/image.png?auth_key=1686117517-jseHsfnzAHfkmNZr2AHqsP-0-2a0a1282a639b22d8219759c42ab0301&file_size=549965"></p><p>redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。</p><p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>日志</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客操作指南</title>
    <link href="/2023/06/04/%E5%8D%9A%E5%AE%A2%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/"/>
    <url>/2023/06/04/%E5%8D%9A%E5%AE%A2%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>第一篇文章就先把怎么更新博客说明白吧，就当写个时间胶囊，以防自己忘了😅 ，本篇文章只适合hexo已经搭建好博客，但是不知道怎么更新的人，网上关于搭建hexo博客的文章也挺多的。</p><p>经过滴滴二面面试官的拷打，我已痛定思痛，开始写技术博客，并且开始注重理论和实践的相结合。</p><ol><li>首先找到自己的blog文件夹（我的blog文件在E盘下），用vscode打开之后找到source下面的_posts文件夹，你的文章就以markdown形式储存在这，你可以先用wolai云笔记记录，之后贴到这里，双重保险不怕丢了，这里主要介绍一下怎么给文章分类和打tag吧。下面这段东西在表头粘上就行</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs Go">---<br>title: Your Article Title<br>date: YYYY-MM-DD HH:MM:SS<br>categories:<br>  - Category1<br>  - Category2<br>tags:<br>  - Tag1<br>  - Tag2<br>---<br></code></pre></td></tr></table></figure><p>2.把文章写进去之后如何推到远端呢，通过下面这三个命令即可，顺序不能乱，原因看完就知道了</p><ul><li><p>hexo g</p><p>  是hexo generate的缩写，把博客文件夹下面的文章转换成HTML静态页面，这些静态页面储存在博客文件夹下的public下面</p></li><li><p>hexo s</p><p>  是hexo server的缩写，把文件夹下的文章在本地的服务器启动，默认端口4000，这时就可以看页面是否符合你的要求，如果符合的话就可以推送到远端了</p></li><li><p>hexo d</p><p>  是hexo deploy的缩写，把页面推送到博客托管平台，一些配置在config下</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>指南</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
